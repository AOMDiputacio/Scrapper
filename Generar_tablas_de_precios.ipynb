{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AOMDiputacio/Scrapper/blob/main/Generar_tablas_de_precios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir del archivo '/content/drive/MyDrive/Scrapper-Pruebadecolchones/url_nombre_a_scrappear.csv'\n"
      ],
      "metadata": {
        "id": "_uKWkop94H-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ikea"
      ],
      "metadata": {
        "id": "GIcsauy8Uikg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests as r\n",
        "import pandas as pd\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Rutas de los archivos en Google Drive\n",
        "ruta_archivo_csv = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/url_nombre_a_scrappear.csv'\n",
        "\n",
        "# Leer el CSV desde Google Drive con especificación de la codificación\n",
        "df_urls = pd.read_csv(ruta_archivo_csv, encoding='latin1')\n",
        "\n",
        "# Check for NaN values in the 'URL' column\n",
        "df_urls = df_urls.dropna(subset=['URL'])\n",
        "\n",
        "# Filtrar las filas que contienen 'ikea.com' en la columna 'url'\n",
        "df_urls = df_urls[df_urls['URL'].str.contains('ikea.com')]\n",
        "\n",
        "# Obtener la lista de URLs, nombres, y variantes desde el DataFrame\n",
        "urles = df_urls['URL'].tolist()\n",
        "nombres = df_urls['Nombre'].tolist()\n",
        "\n",
        "# Inicializar la lista json_list\n",
        "json_list = []\n",
        "\n",
        "# Iterar sobre las URLs y obtener información\n",
        "for url, nombre in zip(urles, nombres):\n",
        "    # Conseguir URL por dimensión por el modelo seleccionado\n",
        "\n",
        "    try:\n",
        "        reql = r.get(url)\n",
        "        reql.raise_for_status()  # Verificar si hay errores en la solicitud HTTP\n",
        "        soup = BeautifulSoup(reql.text, \"html.parser\")\n",
        "        urldim = soup.find_all('div', class_='js-product-variation-section pip-product-variation-section')\n",
        "\n",
        "        for div in urldim:\n",
        "            data_initial_props = div['data-initial-props']\n",
        "            json_data = json.loads(data_initial_props)\n",
        "\n",
        "            # Obtener información del precio anidado\n",
        "            for option in json_data['variations'][0]['options']:\n",
        "                price_props = option['priceProps']\n",
        "                precio_original = price_props.get('priceNumeral')\n",
        "                dimension = option['title']\n",
        "\n",
        "                # Agregar a la lista si priceNumeral está presente\n",
        "                if precio_original is not None:\n",
        "                    json_list.append({'nombre': nombre, 'dimension': dimension, 'precio_original': precio_original, 'precio_con_descuento': precio_original})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar la URL: {url}\")\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# Crear un DataFrame con la información de \"priceNumeral\" y \"dimension\"\n",
        "matriz_precios_ikea = pd.DataFrame(json_list, columns=['nombre', 'dimension', 'precio_original', 'precio_con_descuento'])\n",
        "\n",
        "# Mostrar el DataFrame\n",
        "print(matriz_precios_ikea)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAY3iHqsrORK",
        "outputId": "dc47a8cd-d253-463c-ece9-0a1aa89f73ec"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "           nombre   dimension  precio_original  precio_con_descuento\n",
            "0    IKEA Valevag   80x200 cm              199                   199\n",
            "1    IKEA Valevag   90x190 cm              199                   199\n",
            "2    IKEA Valevag   90x200 cm              199                   199\n",
            "3    IKEA Valevag  105x190 cm              269                   269\n",
            "4    IKEA Valevag  135x190 cm              299                   299\n",
            "5    IKEA Valevag  140x200 cm              299                   299\n",
            "6    IKEA Valevag  150x190 cm              369                   369\n",
            "7    IKEA Valevag  160x200 cm              369                   369\n",
            "8    IKEA Valevag  180x200 cm              459                   459\n",
            "9   IKEA Vesteroy   80x200 cm              169                   169\n",
            "10  IKEA Vesteroy   90x190 cm              169                   169\n",
            "11  IKEA Vesteroy   90x200 cm              169                   169\n",
            "12  IKEA Vesteroy  105x190 cm              199                   199\n",
            "13  IKEA Vesteroy  135x190 cm              199                   199\n",
            "14  IKEA Vesteroy  140x200 cm              199                   199\n",
            "15  IKEA Vesteroy  150x190 cm              299                   299\n",
            "16  IKEA Vesteroy  160x200 cm              299                   299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests as r\n",
        "import pandas as pd\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Rutas de los archivos en Google Drive\n",
        "ruta_archivo_csv = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/url_nombre_a_scrappear.csv'\n",
        "\n",
        "# Leer el CSV desde Google Drive con especificación de la codificación\n",
        "df_urls = pd.read_csv(ruta_archivo_csv, encoding='latin1')\n",
        "\n",
        "# Check for NaN values in the 'URL' column\n",
        "df_urls = df_urls.dropna(subset=['URL'])\n",
        "\n",
        "# Filtrar las filas que contienen 'ikea.com' en la columna 'url'\n",
        "df_urls = df_urls[df_urls['URL'].str.contains('ikea.com')]\n",
        "\n",
        "# Obtener la lista de URLs, nombres, y variantes desde el DataFrame\n",
        "urles = df_urls['URL'].tolist()\n",
        "nombres = df_urls['Nombre'].tolist()\n",
        "\n",
        "# Inicializar la lista json_list\n",
        "json_list = []\n",
        "\n",
        "# Iterar sobre las URLs y obtener información\n",
        "for url, nombre in zip(urles, nombres):\n",
        "    # Conseguir URL por dimensión por el modelo seleccionado\n",
        "    url = url + \"#content\"\n",
        "\n",
        "    try:\n",
        "        reql = r.get(url)\n",
        "        reql.raise_for_status()  # Verificar si hay errores en la solicitud HTTP\n",
        "        soup = BeautifulSoup(reql.text, \"html.parser\")\n",
        "        urldim = soup.find_all('div', class_='js-product-variation-section pip-product-variation-section')\n",
        "\n",
        "        for div in urldim:\n",
        "            data_initial_props = div['data-initial-props']\n",
        "            json_data = json.loads(data_initial_props)\n",
        "\n",
        "            # Obtener información del precio anidado\n",
        "            for option in json_data['variations'][0]['options']:\n",
        "                price_props = option['priceProps']\n",
        "                precio_original = price_props.get('priceNumeral')\n",
        "                title = option['title']\n",
        "\n",
        "                # Agregar a la lista si priceNumeral está presente\n",
        "                if precio_original is not None:\n",
        "                    json_list.append({'priceNumeral': precio_original, 'title': title})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar la URL: {url}\")\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# Crear un DataFrame con la información de \"priceNumeral\" y \"title\"\n",
        "df = pd.DataFrame(json_list, columns=['title','priceNumeral','priceNumeral' ])\n",
        "\n",
        "# Mostrar el DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm6oziUrjZbP",
        "outputId": "2548d6f4-21c1-465d-d025-df13debd7d74"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "         title  priceNumeral  priceNumeral\n",
            "0    80x200 cm           199           199\n",
            "1    90x190 cm           199           199\n",
            "2    90x200 cm           199           199\n",
            "3   105x190 cm           269           269\n",
            "4   135x190 cm           299           299\n",
            "5   140x200 cm           299           299\n",
            "6   150x190 cm           369           369\n",
            "7   160x200 cm           369           369\n",
            "8   180x200 cm           459           459\n",
            "9    80x200 cm           169           169\n",
            "10   90x190 cm           169           169\n",
            "11   90x200 cm           169           169\n",
            "12  105x190 cm           199           199\n",
            "13  135x190 cm           199           199\n",
            "14  140x200 cm           199           199\n",
            "15  150x190 cm           299           299\n",
            "16  160x200 cm           299           299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests as r\n",
        "import pandas as pd\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Rutas de los archivos en Google Drive\n",
        "ruta_archivo_csv = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/url_nombre_a_scrappear.csv'\n",
        "\n",
        "# Leer el CSV desde Google Drive con especificación de la codificación\n",
        "df_urls = pd.read_csv(ruta_archivo_csv, encoding='latin1')\n",
        "\n",
        "# Check for NaN values in the 'URL' column\n",
        "df_urls = df_urls.dropna(subset=['URL'])\n",
        "\n",
        "# Filtrar las filas que contienen 'hypnia.es' en la columna 'url'\n",
        "df_urls = df_urls[df_urls['URL'].str.contains('ikea.com')]\n",
        "\n",
        "# Obtener la lista de URLs, nombres, y variantes desde el DataFrame\n",
        "urles = df_urls['URL'].tolist()\n",
        "nombres = df_urls['Nombre'].tolist()\n",
        "\n",
        "print(urles)\n",
        "print(nombres)\n",
        "\n",
        "url=urles[0]\n",
        "nombre=nombres[0]\n",
        "\n",
        "##Conseguir URL por dimensión por el modelo seleccionado\n",
        "url = url + \"#content\"\n",
        "reql = r.get(url)\n",
        "soup = BeautifulSoup(reql.text, \"html.parser\")\n",
        "urldim = soup.find_all('div', class_='js-product-variation-section pip-product-variation-section')\n",
        "for div in urldim:\n",
        "    data_initial_props = div['data-initial-props']\n",
        "    json_data = json.loads(data_initial_props)\n",
        "    json_list.extend(json_data['variations'][0]['options'])\n",
        "\n",
        "# Crear un DataFrame con la información de \"priceNumeral\" y \"title\"\n",
        "df = pd.DataFrame(json_list, columns=['priceNumeral', 'title'])\n",
        "\n",
        "# Mostrar el DataFrame\n",
        "print(df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBun5PrBUh3k",
        "outputId": "fb29261a-8431-4ab1-b3c7-14805636e4b0"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['https://www.ikea.com/es/es/p/valevag-colchon-muelles-ensacados-firme-azul-claro-80531731/', 'https://www.ikea.com/es/es/p/vesteroy-colchon-muelles-ensacados-firme-azul-claro-30450609/']\n",
            "['IKEA Valevag', 'IKEA Vesteroy']\n",
            "    priceNumeral       title\n",
            "0          199.0   80x200 cm\n",
            "1          199.0   90x190 cm\n",
            "2          199.0   90x200 cm\n",
            "3          269.0  105x190 cm\n",
            "4          299.0  135x190 cm\n",
            "5          299.0  140x200 cm\n",
            "6          369.0  150x190 cm\n",
            "7          369.0  160x200 cm\n",
            "8          459.0  180x200 cm\n",
            "9          169.0   80x200 cm\n",
            "10         169.0   90x190 cm\n",
            "11         169.0   90x200 cm\n",
            "12         199.0  105x190 cm\n",
            "13         199.0  135x190 cm\n",
            "14         199.0  140x200 cm\n",
            "15         299.0  150x190 cm\n",
            "16         299.0  160x200 cm\n",
            "17           NaN   80x200 cm\n",
            "18           NaN   90x190 cm\n",
            "19           NaN   90x200 cm\n",
            "20           NaN  105x190 cm\n",
            "21           NaN  135x190 cm\n",
            "22           NaN  140x200 cm\n",
            "23           NaN  150x190 cm\n",
            "24           NaN  160x200 cm\n",
            "25           NaN  180x200 cm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hypnia"
      ],
      "metadata": {
        "id": "HXnhDD6zo41-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests as r\n",
        "import pandas as pd\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Rutas de los archivos en Google Drive\n",
        "ruta_archivo_csv = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/url_nombre_a_scrappear.csv'\n",
        "\n",
        "# Leer el CSV desde Google Drive con especificación de la codificación\n",
        "df_urls = pd.read_csv(ruta_archivo_csv, encoding='latin1')\n",
        "\n",
        "# Check for NaN values in the 'URL' column\n",
        "df_urls = df_urls.dropna(subset=['URL'])\n",
        "\n",
        "# Filtrar las filas que contienen 'hypnia.es' en la columna 'url'\n",
        "df_urls = df_urls[df_urls['URL'].str.contains('hypnia.es')]\n",
        "\n",
        "# Obtener la lista de URLs, nombres, y variantes desde el DataFrame\n",
        "urles = df_urls['URL'].tolist()\n",
        "nombres = df_urls['Nombre'].tolist()\n",
        "urles = [urle + \"?variant=\" for urle in urles]\n",
        "\n",
        "# Crear una lista para almacenar los DataFrames de cada URL\n",
        "dfs = []\n",
        "\n",
        "# Iterar sobre las URLs\n",
        "for urle, nombre in zip(urles, nombres):  # Iterate over both URL and nombre simultaneously\n",
        "\n",
        "    # Función para obtener precios desde la URL\n",
        "    def obtener_precios(id):\n",
        "        url = f\"{urle}{id}\"\n",
        "        reql = r.get(url)\n",
        "        soup = BeautifulSoup(reql.text, \"html.parser\")\n",
        "        precios = soup.find('div', class_='product_price')\n",
        "\n",
        "        if precios:\n",
        "            precio_original = precios.find('s').text if precios.find('s') else None\n",
        "            precio_con_descuento = precios.find_all('span')[1].text if len(precios.find_all('span')) > 1 else None\n",
        "            return precio_original, precio_con_descuento\n",
        "        else:\n",
        "            return None, None\n",
        "\n",
        "    # Obtener el contenido de la página\n",
        "    reql = r.get(urle)\n",
        "    soup = BeautifulSoup(reql.text, \"html.parser\")\n",
        "\n",
        "    # Encontrar todos los scripts con type 'application/json'\n",
        "    scripts = soup.find_all('script', type='application/json')\n",
        "\n",
        "    # Iterar sobre los scripts y encontrar el que contiene datos relevantes\n",
        "    for script in scripts:\n",
        "        if \"name\" in script.string:\n",
        "            schema = script.string\n",
        "            break\n",
        "\n",
        "    # Extraer datos del JSON\n",
        "    data = json.loads(schema)\n",
        "\n",
        "    # Crear DataFrame\n",
        "    df = pd.DataFrame(data, columns=[\"name\", \"id\", \"title\", \"price\"])\n",
        "\n",
        "    # Renombrar columnas\n",
        "    df.columns = [\"name\", \"id\", \"title\", \"price\"]\n",
        "\n",
        "    # Agregar una columna 'nombre' al DataFrame\n",
        "    df['nombre'] = nombre\n",
        "\n",
        "    # Iterar sobre cada fila del DataFrame y añadir las columnas\n",
        "    for index, row in df.iterrows():\n",
        "        id_variant = row['id']\n",
        "        precio_original, precio_con_descuento = obtener_precios(id_variant)\n",
        "        df.at[index, 'precio_original'] = precio_original\n",
        "        df.at[index, 'precio_con_descuento'] = precio_con_descuento\n",
        "\n",
        "    # Agregar el DataFrame a la lista\n",
        "    dfs.append(df)\n",
        "\n",
        "# Concatenar todos los DataFrames en uno solo\n",
        "final_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "# Formatear tabla y columnas\n",
        "\n",
        "# Definir una función para formatear precios y limpiar título\n",
        "def formatear_datos(row):\n",
        "    # Formatear precios\n",
        "    for columna_precio in ['precio_original', 'precio_con_descuento']:\n",
        "        if pd.notna(row[columna_precio]):\n",
        "            # Eliminar el símbolo € y el punto de miles, luego reemplazar la coma decimal por un punto y eliminar espacios\n",
        "            row[columna_precio] = str(row[columna_precio]).replace('€', '').replace('.', '').replace(' ', '')\n",
        "            # Agregar el punto decimal para indicar decimales\n",
        "            row[columna_precio] = row[columna_precio].replace(',', '.', 1)\n",
        "\n",
        "    # Limpiar título y suprimir espacios\n",
        "    if ' (cm)' in row['title']:\n",
        "        row['title'] = row['title'].split(' (cm)')[0].replace(' ', '')\n",
        "\n",
        "    return row\n",
        "\n",
        "# Aplicar la función a las filas del DataFrame\n",
        "final_df = final_df.apply(formatear_datos, axis=1)\n",
        "\n",
        "#cambiar nombre de columna\n",
        "final_df.rename(columns={'title': 'dimension'}, inplace=True)\n",
        "\n",
        "# Mostrar solo las últimas tres columnas del DataFrame\n",
        "#print(final_df[['nombre', 'label', 'precio_original', 'precio_con_descuento']])\n",
        "\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas deseadas\n",
        "matriz_precios_hypnia = final_df[['nombre', 'dimension', 'precio_original', 'precio_con_descuento']]\n",
        "\n",
        "# Imprimir el resultado\n",
        "print(matriz_precios_hypnia)\n",
        "\n",
        "# Subir resultados en Google drive\n",
        "\n",
        "# Rutas de los archivos en Google Drive\n",
        "ruta_archivo_json = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/matriz_hypnia.json'\n",
        "ruta_archivo_csv = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/matriz_hypnia.csv'\n",
        "\n",
        "# Guardar el DataFrame en un archivo JSON en Google Drive\n",
        "#matriz_precios_hypnia.to_json(ruta_archivo_json, orient='records', lines=True)\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV en Google Drive\n",
        "#matriz_precios_hypnia.to_csv(ruta_archivo_csv, index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x6_PfOq7oa2",
        "outputId": "98cbfef8-73d4-4c84-b1c1-eab5fcec8fb9"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "                            nombre        dimension precio_original  \\\n",
            "0    Almohada Efecto Plumas Hypnia  40 x 70 cm (x2)           99.00   \n",
            "1       Almohada Ergonómica Hypnia    56 x 36 cm x2          128.00   \n",
            "2       Almohada Ergonómica Hypnia       56 x 36 cm           70.00   \n",
            "3          Almohada Luna de Hypnia            50x70           55.00   \n",
            "4          Almohada Luna de Hypnia            50x70           99.00   \n",
            "..                             ...              ...             ...   \n",
            "152       Topper Premium de Hypnia          160x200          375.00   \n",
            "153       Topper Premium de Hypnia          180x200          425.00   \n",
            "154                Hypnia Esencial           90x190             NaN   \n",
            "155                Hypnia Esencial          160x200             NaN   \n",
            "156                Hypnia Esencial          180x200             NaN   \n",
            "\n",
            "    precio_con_descuento  \n",
            "0                  49.00  \n",
            "1                  89.00  \n",
            "2                  49.00  \n",
            "3                  49.00  \n",
            "4                  89.00  \n",
            "..                   ...  \n",
            "152               299.00  \n",
            "153               339.00  \n",
            "154                  NaN  \n",
            "155                  NaN  \n",
            "156                  NaN  \n",
            "\n",
            "[157 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pikolin\n"
      ],
      "metadata": {
        "id": "srg0l94LKACf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests as r\n",
        "import pandas as pd\n",
        "import json\n",
        "from google.colab import drive\n",
        "import re\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Rutas de los archivos en Google Drive\n",
        "ruta_archivo_csv = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/url_nombre_a_scrappear.csv'\n",
        "\n",
        "# Leer el CSV desde Google Drive con especificación de la codificación\n",
        "df_urls = pd.read_csv(ruta_archivo_csv, encoding='latin1')\n",
        "\n",
        "# Check for NaN values in the 'URL' column\n",
        "df_urls = df_urls.dropna(subset=['URL'])\n",
        "\n",
        "# Filtrar las filas que contienen 'pikolin.com' en la columna 'URL'\n",
        "df_urls_pikolin = df_urls[df_urls['URL'].str.contains('pikolin.com')]\n",
        "\n",
        "# Inicializar una lista vacía para almacenar los resultados de cada fila\n",
        "results_list = []\n",
        "\n",
        "def extract_json_objects(script_tags):\n",
        "    json_objects = []\n",
        "    for script_tag in script_tags:\n",
        "        try:\n",
        "            if script_tag.string:\n",
        "                json_content = json.loads(script_tag.string)\n",
        "                json_objects.append(json_content)\n",
        "\n",
        "                pattern = r'\"defaultProductId\": (\\d+)'\n",
        "                match = re.search(pattern, script_tag.string)\n",
        "\n",
        "                if match:\n",
        "                    default_product_id = match.group(1)\n",
        "                    target_product_id = default_product_id\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error al decodificar JSON en la etiqueta de script:\\n{script_tag}\\nError: {e}\")\n",
        "\n",
        "    return json_objects, target_product_id\n",
        "\n",
        "def get_product_data(json_content, target_product_id):\n",
        "    product_id_data = json_content.get(f\"[product-id='{target_product_id}']\", {}).get(\"Magento_Swatches/js/swatch-renderer\", {}).get(\"jsonConfig\", {}).get(\"attributes\", {})\n",
        "    return product_id_data\n",
        "\n",
        "def create_table(data, column_names):\n",
        "    table = pd.DataFrame(data, columns=column_names)\n",
        "    return table\n",
        "\n",
        "# Iterar a través de todas las filas en df_urls_pikolin\n",
        "for index, row in df_urls_pikolin.iterrows():\n",
        "    url = row['URL']\n",
        "    nombre = row['Nombre']\n",
        "\n",
        "    # Realizar una solicitud para la URL actual\n",
        "    response = r.get(url)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Encontrar todas las etiquetas de script\n",
        "    script_tags = soup.find_all('script', {'type': 'text/x-magento-init'})\n",
        "\n",
        "    # Extraer objetos JSON de las etiquetas de script\n",
        "    json_objects, target_product_id = extract_json_objects(script_tags)\n",
        "\n",
        "    # Extract JSON objects from script tags\n",
        "    for script_tag in script_tags:\n",
        "        try:\n",
        "            # Check if the 'string' attribute is not None\n",
        "            if script_tag.string:\n",
        "                # Check if the script tag contains the target product ID\n",
        "                if f'\"[product-id=\\'{target_product_id}\\']\":' in script_tag.string:\n",
        "                    # Parse the text content of the script tag as JSON\n",
        "                    json_content = json.loads(script_tag.string)\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON in script tag:\\n{script_tag}\\nError: {e}\")\n",
        "\n",
        "    # Obtener datos relacionados con el producto usando el ID del producto\n",
        "    product_id_data = get_product_data(json_content, target_product_id)\n",
        "\n",
        "    # Crear una tabla con columnas 'Id', 'label' y 'products'\n",
        "    column_names1 = ['Id', 'label', 'products']\n",
        "    table1_data = [{'Id': option['id'], 'label': option['label'], 'products': ', '.join(option['products'])} for option in product_id_data.get('272', {}).get('options', [])]\n",
        "    df_table1 = create_table(table1_data, column_names1)\n",
        "\n",
        "    # Obtener datos de precios de opciones\n",
        "    option_prices_data = json_content.get(f\"[product-id='{target_product_id}']\", {}).get(\"Magento_Swatches/js/swatch-renderer\", {}).get(\"jsonConfig\", {}).get(\"optionPrices\", {})\n",
        "\n",
        "    # Crear una tabla con columnas 'Label', 'Old Price' y 'Final Price'\n",
        "    column_names2 = ['Label', 'Old Price', 'Final Price']\n",
        "    table2_data = [{'Label': label, 'Old Price': prices['oldPrice']['amount'], 'Final Price': prices['finalPrice']['amount']} for label, prices in option_prices_data.items()]\n",
        "    df_table2 = create_table(table2_data, column_names2)\n",
        "\n",
        "    # Fusionar las tablas en columnas clave comunes\n",
        "    merged_table = pd.merge(df_table1, df_table2, left_on=['products'], right_on=['Label'], how='left')\n",
        "\n",
        "    # Crear una nueva columna 'nombre' en merged_table con el mismo valor para todas las filas\n",
        "    merged_table.insert(0, 'nombre', nombre)\n",
        "\n",
        "    # Agregar la tabla fusionada a la lista de resultados\n",
        "    results_list.append(merged_table)\n",
        "\n",
        "# Concatenar todos los resultados en un solo DataFrame\n",
        "final_result = pd.concat(results_list, ignore_index=True)\n",
        "\n",
        "# Eliminar las columnas 'label' y 'products'\n",
        "final_result = final_result.drop(final_result.columns[[1, 3, 4]], axis=1)\n",
        "\n",
        "# Imprimir el resultado final\n",
        "matriz_precios_pikolin = final_result\n",
        "\n",
        "matriz_precios_pikolin.rename(columns={'label': 'dimension', 'Old Price': 'precio_original', 'Final Price': 'precio_con_descuento'}, inplace=True)\n",
        "\n",
        "print(matriz_precios_pikolin)\n",
        "\n",
        "# Subir resultados en Google drive\n",
        "\n",
        "# Montar Google Drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Rutas de los archivos en Google Drive\n",
        "ruta_archivo_json = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/matriz_pikolin.json'\n",
        "ruta_archivo_csv = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/matriz_pikolin.csv'\n",
        "\n",
        "# Guardar el DataFrame en un archivo JSON en Google Drive\n",
        "#final_result.to_json(ruta_archivo_json, orient='records', lines=True)\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV en Google Drive\n",
        "#final_result.to_csv(ruta_archivo_csv, index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpGujWEJAbgY",
        "outputId": "a0612a67-6d83-4e91-c2cb-03c1a0df1ca0"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "             nombre dimension  precio_original  precio_con_descuento\n",
            "0      Pikolin City    90x190            733.0                 366.5\n",
            "1      Pikolin City   105x190            813.0                 406.5\n",
            "2      Pikolin City   135X190            977.0                 488.5\n",
            "3      Pikolin City   150X190           1115.0                 557.5\n",
            "4      Pikolin City   150X200           1227.0                 613.5\n",
            "..              ...       ...              ...                   ...\n",
            "64  Pikolin Marisma    90x200           1250.0                 562.5\n",
            "65  Pikolin Marisma   105x200           1390.0                 625.5\n",
            "66  Pikolin Marisma   160x190           1840.0                 828.0\n",
            "67  Pikolin Marisma   135X200           1558.0                 701.1\n",
            "68  Pikolin Marisma   180X200           2182.0                 981.9\n",
            "\n",
            "[69 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Emma\n"
      ],
      "metadata": {
        "id": "LchkwI1MGuaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Rutas de los archivos en Google Drive\n",
        "ruta_archivo_csv = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/url_nombre_a_scrappear.csv'\n",
        "\n",
        "# Leer el CSV desde Google Drive con especificación de la codificación\n",
        "df_urls = pd.read_csv(ruta_archivo_csv, encoding='latin1')\n",
        "\n",
        "# Check for NaN values in the 'URL' column\n",
        "df_urls = df_urls.dropna(subset=['URL'])\n",
        "\n",
        "# Filtrar las filas que contienen 'emma-colchon.es' en la columna 'url'\n",
        "df_urls = df_urls[df_urls['URL'].str.contains('emma-colchon.es')]\n",
        "\n",
        "# Inicializar una lista para almacenar los DataFrames resultantes\n",
        "resultados = []\n",
        "\n",
        "# Iterar sobre cada URL en df_urls\n",
        "for index, row in df_urls.iterrows():\n",
        "    url = row['URL']\n",
        "    nombre = row['Nombre']\n",
        "    descuento = row['Descuento']\n",
        "\n",
        "    # Realizar la solicitud HTTP\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Verificar si la solicitud fue exitosa (código 200)\n",
        "    if response.status_code == 200:\n",
        "        # Obtener el contenido HTML\n",
        "        html_content = response.text\n",
        "\n",
        "        # Crear un objeto BeautifulSoup para analizar el HTML\n",
        "        soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "        # Encontrar el script con id=\"structured-data_0\"\n",
        "        target_script = soup.find('script', {'id': 'structured-data_0'})\n",
        "\n",
        "        # Extraer el contenido del script si se encuentra\n",
        "        if target_script:\n",
        "            # Obtener el contenido del script como texto\n",
        "            script_content = target_script.string\n",
        "\n",
        "            # Cargar el JSON desde el script\n",
        "            data = json.loads(script_content)\n",
        "\n",
        "            # Crear un DataFrame de pandas\n",
        "            df = pd.DataFrame(data)\n",
        "\n",
        "            # Seleccionar las columnas 'name' y 'offers'\n",
        "            df = df[['name', 'offers']]\n",
        "\n",
        "            # Expandir la columna 'offers' en nuevas columnas\n",
        "            df = pd.concat([df.drop(['offers'], axis=1), df['offers'].apply(pd.Series)], axis=1)\n",
        "\n",
        "            # Renombrar columnas'\n",
        "            df = df.rename(columns={'name': 'lbl'})\n",
        "            df = df.rename(columns={'price': 'precio_con_descuento'})\n",
        "\n",
        "            # Seleccionar las columnas finales\n",
        "            df = df[['lbl', 'precio_con_descuento']]\n",
        "\n",
        "            # Conservar solo la parte después del último espacio en la columna 'lbl'\n",
        "            df['lbl'] = df['lbl'].apply(lambda x: x.split(' ')[-1])\n",
        "\n",
        "            # Añadir las columnas 'nombre' y 'precio original'\n",
        "            df['nombre'] = nombre\n",
        "            df['precio_con_descuento'] = pd.to_numeric(df['precio_con_descuento'], errors='coerce')\n",
        "            descuento_numerico = float(descuento.strip('%')) / 100\n",
        "            df['precio_original'] = round(df['precio_con_descuento'] / (1 - descuento_numerico), 2) if descuento_numerico != 0 else round(df['price'], 2)\n",
        "\n",
        "            # Reorganizar las columnas para colocar 'nombre' en la primera posición\n",
        "            df = df[['nombre', 'lbl', 'precio_original', 'precio_con_descuento']]\n",
        "\n",
        "            # Agregar el DataFrame resultante a la lista\n",
        "            resultados.append(df)\n",
        "        else:\n",
        "            print(f\"No se encontró un script con id='structured-data_0' en la URL: {url}\")\n",
        "    else:\n",
        "        print(f\"Fallo al recuperar la página web. Código de estado: {response.status_code} en la URL: {url}\")\n",
        "\n",
        "# Concatenar todos los DataFrames en uno solo\n",
        "resultado_final = pd.concat(resultados, ignore_index=True)\n",
        "\n",
        "# Imprimir el DataFrame final\n",
        "matriz_precios_emma = resultado_final\n",
        "\n",
        "matriz_precios_emma.rename(columns={'lbl': 'dimension'}, inplace=True)\n",
        "\n",
        "print(matriz_precios_emma)\n",
        "\n",
        "# Rutas de los archivos en Google Drive\n",
        "ruta_archivo_json = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/matriz_emma.json'\n",
        "ruta_archivo_csv = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/matriz_emma.csv'\n",
        "\n",
        "# Guardar el DataFrame en un archivo JSON en Google Drive\n",
        "# resultado_final.to_json(ruta_archivo_json, orient='records', lines=True)\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV en Google Drive\n",
        "#resultado_final.to_csv(ruta_archivo_csv, index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jywlsqfn4_Hs",
        "outputId": "7950be1e-e0c9-496a-f204-4c8d32f80b1f"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "                                 nombre dimension  precio_original  \\\n",
            "0              Almohada Microfibra Emma     40x70            37.37   \n",
            "1   Almohada Viscoelástica Premium Emma     70x40            99.86   \n",
            "2                    Base Tapizada Emma    90x190           242.71   \n",
            "3                    Base Tapizada Emma   135x190           342.71   \n",
            "4                    Base Tapizada Emma   150x190           385.57   \n",
            "..                                  ...       ...              ...   \n",
            "67                   Cama Tapizada Emma   135x190           599.87   \n",
            "68                   Cama Tapizada Emma   140x200           642.73   \n",
            "69                   Cama Tapizada Emma   140x200           471.30   \n",
            "70                   Cama Tapizada Emma   150x200           699.87   \n",
            "71                   Cama Tapizada Emma   150x200           528.44   \n",
            "\n",
            "    precio_con_descuento  \n",
            "0                  29.90  \n",
            "1                  69.90  \n",
            "2                 169.90  \n",
            "3                 239.90  \n",
            "4                 269.90  \n",
            "..                   ...  \n",
            "67                419.91  \n",
            "68                449.91  \n",
            "69                329.91  \n",
            "70                489.91  \n",
            "71                369.91  \n",
            "\n",
            "[72 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Juntando todas las tablas"
      ],
      "metadata": {
        "id": "F1KgDkuAr_DH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtén las 4 primeras columnas de cada DataFrame\n",
        "column_indices = [0, 1, 2, 3]\n",
        "\n",
        "# Selecciona las columnas deseadas de cada DataFrame\n",
        "hypnia_selected_columns = matriz_precios_hypnia.iloc[:, column_indices]\n",
        "pikolin_selected_columns = matriz_precios_pikolin.iloc[:, column_indices]\n",
        "emma_selected_columns = matriz_precios_emma.iloc[:, column_indices]\n",
        "ikea_selected_columns = matriz_precios_ikea.iloc[:, column_indices]\n",
        "\n",
        "# Concatena los DataFrames seleccionados\n",
        "matriz_precios_scrapping = pd.concat([hypnia_selected_columns, pikolin_selected_columns, emma_selected_columns, ikea_selected_columns], ignore_index=True)\n",
        "\n",
        "matriz_precios_scrapping = matriz_precios_scrapping.iloc[:, column_indices]\n",
        "\n",
        "# Asigna nombres a las columnas resultantes\n",
        "matriz_precios_scrapping.columns = ['nombre', 'dimension', 'precio_original', 'precio_con_descuento']\n",
        "\n",
        "# Imprimir el resultado\n",
        "print(matriz_precios_scrapping)\n",
        "\n",
        "#formato a convertir a json\n",
        "\n",
        "matriz_precios_prejson = matriz_precios_scrapping.rename(columns={\n",
        "    'nombre': 'name',\n",
        "    'dimension': 'var1_item',\n",
        "    'precio_original': 'price',\n",
        "    'precio_con_descuento': 'promo'\n",
        "})\n",
        "print(matriz_precios_prejson)\n",
        "# Subir resultados en Google drive\n",
        "\n",
        "# Rutas de los archivos en Google Drive\n",
        "ruta_archivo_json = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/matriz_precios_scrapping.json'\n",
        "ruta_archivo_csv = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/matriz_precios_scrapping.csv'\n",
        "\n",
        "# Guardar el DataFrame en un archivo JSON en Google Drive\n",
        "#matriz_precios_scrapping.to_json(ruta_archivo_json, orient='records', lines=True)\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV en Google Drive\n",
        "matriz_precios_scrapping.to_csv(ruta_archivo_csv, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAnzHoz6sFTg",
        "outputId": "553606de-05a8-4ccc-efdf-87e3832c812b"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            nombre        dimension precio_original  \\\n",
            "0    Almohada Efecto Plumas Hypnia  40 x 70 cm (x2)           99.00   \n",
            "1       Almohada Ergonómica Hypnia    56 x 36 cm x2          128.00   \n",
            "2       Almohada Ergonómica Hypnia       56 x 36 cm           70.00   \n",
            "3          Almohada Luna de Hypnia            50x70           55.00   \n",
            "4          Almohada Luna de Hypnia            50x70           99.00   \n",
            "..                             ...              ...             ...   \n",
            "310                  IKEA Vesteroy       105x190 cm             199   \n",
            "311                  IKEA Vesteroy       135x190 cm             199   \n",
            "312                  IKEA Vesteroy       140x200 cm             199   \n",
            "313                  IKEA Vesteroy       150x190 cm             299   \n",
            "314                  IKEA Vesteroy       160x200 cm             299   \n",
            "\n",
            "    precio_con_descuento  \n",
            "0                  49.00  \n",
            "1                  89.00  \n",
            "2                  49.00  \n",
            "3                  49.00  \n",
            "4                  89.00  \n",
            "..                   ...  \n",
            "310                  199  \n",
            "311                  199  \n",
            "312                  199  \n",
            "313                  299  \n",
            "314                  299  \n",
            "\n",
            "[315 rows x 4 columns]\n",
            "                              name        var1_item   price  promo\n",
            "0    Almohada Efecto Plumas Hypnia  40 x 70 cm (x2)   99.00  49.00\n",
            "1       Almohada Ergonómica Hypnia    56 x 36 cm x2  128.00  89.00\n",
            "2       Almohada Ergonómica Hypnia       56 x 36 cm   70.00  49.00\n",
            "3          Almohada Luna de Hypnia            50x70   55.00  49.00\n",
            "4          Almohada Luna de Hypnia            50x70   99.00  89.00\n",
            "..                             ...              ...     ...    ...\n",
            "310                  IKEA Vesteroy       105x190 cm     199    199\n",
            "311                  IKEA Vesteroy       135x190 cm     199    199\n",
            "312                  IKEA Vesteroy       140x200 cm     199    199\n",
            "313                  IKEA Vesteroy       150x190 cm     299    299\n",
            "314                  IKEA Vesteroy       160x200 cm     299    299\n",
            "\n",
            "[315 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#pruebadecolchones.es"
      ],
      "metadata": {
        "id": "hu38f0Sz5i0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests as r\n",
        "import pandas as pd\n",
        "\n",
        "# Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Rutas de los archivos en Google Drive\n",
        "ruta_archivo_csv = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/url_nombre_a_scrappear.csv'\n",
        "\n",
        "# Leer el CSV desde Google Drive con especificación de la codificación\n",
        "df_urls = pd.read_csv(ruta_archivo_csv, encoding='latin1')\n",
        "\n",
        "# Check for NaN values in the 'URL' column\n",
        "df_urls = df_urls.dropna(subset=['URL'])\n",
        "\n",
        "# Filtrar las filas que contienen 'pruebadecolchones.es' en la columna 'url'\n",
        "df_urls = df_urls[df_urls['URL'].str.contains('pruebadecolchones.es')]\n",
        "\n",
        "# Crear listas para almacenar los DataFrames individuales\n",
        "dataframes = []\n",
        "\n",
        "# Iterar sobre cada fila en el DataFrame df_urls\n",
        "for index, row in df_urls.iterrows():\n",
        "    url = row['URL']\n",
        "    nombre = row['Nombre']\n",
        "\n",
        "    # Realizar la solicitud y el scraping\n",
        "    reql = r.get(url)\n",
        "    soup = BeautifulSoup(reql.text, \"html.parser\")\n",
        "    widget = soup.find_all('div', class_='flex flex-col items-center w-1/2 md:w-1/3 my-6 md:my-2 text-center')\n",
        "\n",
        "    # Crear listas para almacenar los valores de cada columna\n",
        "    nombres = []\n",
        "    dimensiones = []\n",
        "    precios_originales = []\n",
        "    precios_con_descuento = []\n",
        "\n",
        "    # Iterar sobre cada elemento en la lista 'widget'\n",
        "    for element in widget:\n",
        "        # Para cada elemento, encuentra todos los elementos 'p' y extrae el texto\n",
        "        prices = element.find_all('p')\n",
        "\n",
        "        # Realizar limpieza y guardar los valores en las listas correspondientes\n",
        "        nombre = nombre\n",
        "        dim = prices[0].text.strip().replace(' cm', '') if prices and len(prices) >= 1 else None\n",
        "        precios_ori = prices[2].text.strip().replace(' €', '') if prices and len(prices) >= 3 else None\n",
        "        precios_desc = prices[3].text.strip().replace(' €', '') if prices and len(prices) >= 4 else None\n",
        "\n",
        "        nombres.append(nombre)\n",
        "        dimensiones.append(dim)\n",
        "        precios_originales.append(precios_ori)\n",
        "        precios_con_descuento.append(precios_desc)\n",
        "\n",
        "    # Crear un diccionario con las listas\n",
        "    data = {\n",
        "        'nombre': nombres,\n",
        "        'dimension': dimensiones,\n",
        "        'precio_original': precios_originales,\n",
        "        'precio_con_descuento': precios_con_descuento\n",
        "    }\n",
        "\n",
        "    # Convertir el diccionario en un DataFrame de pandas\n",
        "    df_resultado = pd.DataFrame(data)\n",
        "\n",
        "    # Agregar el DataFrame resultante a la lista\n",
        "    dataframes.append(df_resultado)\n",
        "\n",
        "# Concatenar todos los DataFrames en uno\n",
        "matriz_precios_pruebadecolchones = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "\n",
        "# Rellenar el valor de precio_con_descuento con precio_original cuando está vacío\n",
        "matriz_precios_pruebadecolchones['precio_con_descuento'].fillna(matriz_precios_pruebadecolchones['precio_original'], inplace=True)\n",
        "\n",
        "# Imprimir el DataFrame final\n",
        "print(matriz_precios_pruebadecolchones)\n",
        "\n",
        "\n",
        "\n",
        "# Subir resultados en Google drive\n",
        "\n",
        "# Rutas de los archivos en Google Drive\n",
        "ruta_archivo_json = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/matriz_precios_pruebadecolchones.json'\n",
        "ruta_archivo_csv = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/matriz_precios_pruebadecolchones.csv'\n",
        "\n",
        "# Guardar el DataFrame en un archivo JSON en Google Drive\n",
        "#matriz_precios_pruebadecolchones.to_json(ruta_archivo_json, orient='records', lines=True)\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV en Google Drive\n",
        "#matriz_precios_pruebadecolchones.to_csv(ruta_archivo_csv, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADgzlqaDK8kG",
        "outputId": "106ea5a8-e471-47cc-ebf4-fc6bc989b0e9"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "                        nombre dimension precio_original precio_con_descuento\n",
            "0    Hypnia Bienestar Superior    90x190            689               388.55 \n",
            "1    Hypnia Bienestar Superior    90x200            739               417.05 \n",
            "2    Hypnia Bienestar Superior   135x190            725               550.05 \n",
            "3    Hypnia Bienestar Superior  140 x200           1169               664.05 \n",
            "4    Hypnia Bienestar Superior   150x190           1149               654.55 \n",
            "..                         ...       ...             ...                  ...\n",
            "343  colchon dormio supervisco    90x200          87.39                87.39 \n",
            "344  colchon dormio supervisco   135x190         126.49               126.49 \n",
            "345  colchon dormio supervisco   135x200         134.99               134.99 \n",
            "346  colchon dormio supervisco   150x190         140.09               140.09 \n",
            "347  colchon dormio supervisco   150x200         147.79               147.79 \n",
            "\n",
            "[348 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparar scrapping con pruebadecolchones.es"
      ],
      "metadata": {
        "id": "zSXsaCJDmSyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Definir los porcentajes de descuento\n",
        "descuento_hypnia = 0.05  # 5%\n",
        "descuento_emma = 0.10   # 10%\n",
        "\n",
        "# Función personalizada para aplicar el descuento según el nombre\n",
        "def aplicar_descuento(row):\n",
        "    # Asignar el valor de 'precio_con_descuento' a 'precio_sistema' antes de cualquier transformación\n",
        "    row['precio_sistema'] = row['precio_con_descuento']\n",
        "\n",
        "    if 'hypnia' in row['nombre'].lower():\n",
        "        try:\n",
        "            # Convertir a float, aplicar el descuento y actualizar el valor\n",
        "            row['precio_con_descuento'] = float(row['precio_con_descuento']) * (1 - descuento_hypnia)\n",
        "        except (ValueError, TypeError):\n",
        "            pass\n",
        "    elif 'emma' in row['nombre'].lower():\n",
        "        try:\n",
        "            # Convertir a float, aplicar el descuento y actualizar el valor\n",
        "            row['precio_con_descuento'] = float(row['precio_con_descuento']) * (1 - descuento_emma)\n",
        "        except (ValueError, TypeError):\n",
        "            pass\n",
        "    return row\n",
        "\n",
        "# Aplicar la función a cada fila del DataFrame\n",
        "matriz_precios_scrapping = matriz_precios_scrapping.apply(aplicar_descuento, axis=1)\n",
        "\n",
        "# Imprimir el DataFrame resultante\n",
        "print(matriz_precios_scrapping)\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV en local\n",
        "#matriz_precios_scrapping.to_csv('matriz_precios_scrapping.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg_2MOiRsh5a",
        "outputId": "63b1c3b2-0574-4604-a0d1-ee8503655309"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            nombre        dimension precio_original  \\\n",
            "0    Almohada Efecto Plumas Hypnia  40 x 70 cm (x2)           99.00   \n",
            "1       Almohada Ergonómica Hypnia    56 x 36 cm x2          128.00   \n",
            "2       Almohada Ergonómica Hypnia       56 x 36 cm           70.00   \n",
            "3          Almohada Luna de Hypnia            50x70           55.00   \n",
            "4          Almohada Luna de Hypnia            50x70           99.00   \n",
            "..                             ...              ...             ...   \n",
            "310                  IKEA Vesteroy       105x190 cm             199   \n",
            "311                  IKEA Vesteroy       135x190 cm             199   \n",
            "312                  IKEA Vesteroy       140x200 cm             199   \n",
            "313                  IKEA Vesteroy       150x190 cm             299   \n",
            "314                  IKEA Vesteroy       160x200 cm             299   \n",
            "\n",
            "     precio_con_descuento precio_sistema  \n",
            "0                   46.55          49.00  \n",
            "1                   84.55          89.00  \n",
            "2                   46.55          49.00  \n",
            "3                   46.55          49.00  \n",
            "4                   84.55          89.00  \n",
            "..                    ...            ...  \n",
            "310                199.00            199  \n",
            "311                199.00            199  \n",
            "312                199.00            199  \n",
            "313                299.00            299  \n",
            "314                299.00            299  \n",
            "\n",
            "[315 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Unir DataFrames en base a las claves primarias \"nombre\" y \"dimension\"\n",
        "matriz_compare_precios = pd.merge(matriz_precios_pruebadecolchones, matriz_precios_scrapping, on=['nombre', 'dimension'], how='left')\n",
        "\n",
        "#cambiar nombre columnas\n",
        "matriz_compare_precios = matriz_compare_precios.rename(columns={\n",
        "    'nombre': 'nombre',\n",
        "    'dimension': 'dimension',\n",
        "    'precio_original_x': 'pruebadecolchones_original',\n",
        "    'precio_con_descuento_x': 'pruebadecolchones_promo',\n",
        "    'precio_original_y': 'scrapper_original',\n",
        "    'precio_con_descuento_y': 'scrapper_promo',\n",
        "    'precio_sistema': 'precio_para_sistema'\n",
        "})\n",
        "\n",
        "# Imprimir el DataFrame resultante\n",
        "print(matriz_compare_precios)\n",
        "\n",
        "# Ajustar las listas de orden de columnas según los nombres reales\n",
        "column_order = ['nombre', 'dimension', 'pruebadecolchones_original', 'pruebadecolchones_promo', 'scrapper_original', 'scrapper_promo', 'precio_para_sistema']\n",
        "column_order_second = ['nombre', 'dimension', 'pruebadecolchones_original', 'scrapper_original', 'pruebadecolchones_promo', 'scrapper_promo', 'precio_para_sistema']\n",
        "\n",
        "# Seleccionar solo las columnas necesarias y reordenarlas\n",
        "matriz_compare_precios = matriz_compare_precios[column_order]\n",
        "\n",
        "# Cambiar el orden de las columnas según el segundo orden\n",
        "matriz_compare_precios = matriz_compare_precios[column_order_second]\n",
        "\n",
        "# Sustituir todos los puntos por comas como separador decimal solo en columnas de tipo objeto\n",
        "matriz_compare_precios[matriz_compare_precios.select_dtypes(include='object').columns] = matriz_compare_precios.select_dtypes(include='object').apply(lambda x: x.str.replace('.', ','))\n",
        "\n",
        "print(matriz_compare_precios)\n",
        "\n",
        "# Subir matriz_compare_precios en Google drive\n",
        "\n",
        "# Rutas de los archivos en Google Drive\n",
        "ruta_archivo_json = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/matriz_compare_precios.json'\n",
        "ruta_archivo_csv = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/matriz_compare_precios.csv'\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV en local con punto y coma como separador\n",
        "matriz_compare_precios.to_csv(ruta_archivo_csv, index=False, sep=';')\n",
        "\n",
        "print(\"Tabla guardada\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_8FRHxc9MUH",
        "outputId": "3070fdea-941d-4612-8328-df90195449da"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        nombre dimension pruebadecolchones_original  \\\n",
            "0    Hypnia Bienestar Superior    90x190                       689    \n",
            "1    Hypnia Bienestar Superior    90x200                       739    \n",
            "2    Hypnia Bienestar Superior   135x190                       725    \n",
            "3    Hypnia Bienestar Superior  140 x200                      1169    \n",
            "4    Hypnia Bienestar Superior   150x190                      1149    \n",
            "..                         ...       ...                        ...   \n",
            "352  colchon dormio supervisco    90x200                     87.39    \n",
            "353  colchon dormio supervisco   135x190                    126.49    \n",
            "354  colchon dormio supervisco   135x200                    134.99    \n",
            "355  colchon dormio supervisco   150x190                    140.09    \n",
            "356  colchon dormio supervisco   150x200                    147.79    \n",
            "\n",
            "    pruebadecolchones_promo scrapper_original  scrapper_promo  \\\n",
            "0                   388.55             689.00          388.55   \n",
            "1                   417.05             739.00          417.05   \n",
            "2                   550.05             725.00          550.05   \n",
            "3                   664.05                NaN             NaN   \n",
            "4                   654.55            1149.00          654.55   \n",
            "..                      ...               ...             ...   \n",
            "352                  87.39                NaN             NaN   \n",
            "353                 126.49                NaN             NaN   \n",
            "354                 134.99                NaN             NaN   \n",
            "355                 140.09                NaN             NaN   \n",
            "356                 147.79                NaN             NaN   \n",
            "\n",
            "    precio_para_sistema  \n",
            "0                409.00  \n",
            "1                439.00  \n",
            "2                579.00  \n",
            "3                   NaN  \n",
            "4                689.00  \n",
            "..                  ...  \n",
            "352                 NaN  \n",
            "353                 NaN  \n",
            "354                 NaN  \n",
            "355                 NaN  \n",
            "356                 NaN  \n",
            "\n",
            "[357 rows x 7 columns]\n",
            "                        nombre dimension pruebadecolchones_original  \\\n",
            "0    Hypnia Bienestar Superior    90x190                       689    \n",
            "1    Hypnia Bienestar Superior    90x200                       739    \n",
            "2    Hypnia Bienestar Superior   135x190                       725    \n",
            "3    Hypnia Bienestar Superior  140 x200                      1169    \n",
            "4    Hypnia Bienestar Superior   150x190                      1149    \n",
            "..                         ...       ...                        ...   \n",
            "352  colchon dormio supervisco    90x200                     87,39    \n",
            "353  colchon dormio supervisco   135x190                    126,49    \n",
            "354  colchon dormio supervisco   135x200                    134,99    \n",
            "355  colchon dormio supervisco   150x190                    140,09    \n",
            "356  colchon dormio supervisco   150x200                    147,79    \n",
            "\n",
            "    scrapper_original pruebadecolchones_promo  scrapper_promo  \\\n",
            "0              689,00                 388,55           388.55   \n",
            "1              739,00                 417,05           417.05   \n",
            "2              725,00                 550,05           550.05   \n",
            "3                 NaN                 664,05              NaN   \n",
            "4             1149,00                 654,55           654.55   \n",
            "..                ...                     ...             ...   \n",
            "352               NaN                  87,39              NaN   \n",
            "353               NaN                 126,49              NaN   \n",
            "354               NaN                 134,99              NaN   \n",
            "355               NaN                 140,09              NaN   \n",
            "356               NaN                 147,79              NaN   \n",
            "\n",
            "    precio_para_sistema  \n",
            "0                409,00  \n",
            "1                439,00  \n",
            "2                579,00  \n",
            "3                   NaN  \n",
            "4                689,00  \n",
            "..                  ...  \n",
            "352                 NaN  \n",
            "353                 NaN  \n",
            "354                 NaN  \n",
            "355                 NaN  \n",
            "356                 NaN  \n",
            "\n",
            "[357 rows x 7 columns]\n",
            "Tabla guardada\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-117-575bd44221e5>:29: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  matriz_compare_precios[matriz_compare_precios.select_dtypes(include='object').columns] = matriz_compare_precios.select_dtypes(include='object').apply(lambda x: x.str.replace('.', ','))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original - funciona"
      ],
      "metadata": {
        "id": "GuAXWv3B9ROF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Unir DataFrames en base a las claves primarias \"nombre\" y \"dimension\"\n",
        "matriz_compare_precios = pd.merge(matriz_precios_pruebadecolchones, matriz_precios_scrapping, on=['nombre', 'dimension'], how='left')\n",
        "\n",
        "# Imprimir el DataFrame resultante\n",
        "print(matriz_compare_precios)\n",
        "\n",
        "# Subir matriz_compare_precios en Google drive\n",
        "\n",
        "# Rutas de los archivos en Google Drive\n",
        "ruta_archivo_json = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/matriz_compare_precios.json'\n",
        "ruta_archivo_csv = '/content/drive/MyDrive/Scrapper-Pruebadecolchones/matriz_compare_precios.csv'\n",
        "\n",
        "# Guardar el DataFrame en un archivo JSON en Google Drive\n",
        "#matriz_precios_pruebadecolchones.to_json(ruta_archivo_json, orient='records', lines=True)\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV en Google Drive\n",
        "matriz_compare_precios.to_csv(ruta_archivo_csv, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFw3YqTcZ5Wu",
        "outputId": "ac00215f-fd88-470e-8152-e966f9d13edc"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        nombre dimension precio_original_x  \\\n",
            "0    Hypnia Bienestar Superior    90x190              689    \n",
            "1    Hypnia Bienestar Superior    90x200              739    \n",
            "2    Hypnia Bienestar Superior   135x190              725    \n",
            "3    Hypnia Bienestar Superior  140 x200             1169    \n",
            "4    Hypnia Bienestar Superior   150x190             1149    \n",
            "..                         ...       ...               ...   \n",
            "352  colchon dormio supervisco    90x200            87.39    \n",
            "353  colchon dormio supervisco   135x190           126.49    \n",
            "354  colchon dormio supervisco   135x200           134.99    \n",
            "355  colchon dormio supervisco   150x190           140.09    \n",
            "356  colchon dormio supervisco   150x200           147.79    \n",
            "\n",
            "    precio_con_descuento_x precio_original_y  precio_con_descuento_y  \\\n",
            "0                  388.55             689.00                  388.55   \n",
            "1                  417.05             739.00                  417.05   \n",
            "2                  550.05             725.00                  550.05   \n",
            "3                  664.05                NaN                     NaN   \n",
            "4                  654.55            1149.00                  654.55   \n",
            "..                     ...               ...                     ...   \n",
            "352                 87.39                NaN                     NaN   \n",
            "353                126.49                NaN                     NaN   \n",
            "354                134.99                NaN                     NaN   \n",
            "355                140.09                NaN                     NaN   \n",
            "356                147.79                NaN                     NaN   \n",
            "\n",
            "    precio_sistema  \n",
            "0           409.00  \n",
            "1           439.00  \n",
            "2           579.00  \n",
            "3              NaN  \n",
            "4           689.00  \n",
            "..             ...  \n",
            "352            NaN  \n",
            "353            NaN  \n",
            "354            NaN  \n",
            "355            NaN  \n",
            "356            NaN  \n",
            "\n",
            "[357 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exportar a Bubble"
      ],
      "metadata": {
        "id": "hp_g8F_suapY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FBasLTWqEBSm"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages"
      ],
      "metadata": {
        "id": "lf9ZvxjxJrMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install LINE Python SDK, flask-ngrok\n",
        "!pip install line-bot-sdk\n",
        "!pip install pyngrok\n",
        "[ ]\n",
        "# install LINE Python SDK, flask-ngrok\n",
        "!pip install line-bot-sdk\n",
        "!pip install pyngrok\n",
        "\n",
        "\n",
        "!pip install request\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWVmza5TDUmL",
        "outputId": "7e0018eb-7140-410e-a8f7-03534a11d1cc"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: line-bot-sdk in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (2.0.7)\n",
            "Requirement already satisfied: aiohttp==3.9.0 in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (3.9.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (0.18.3)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (2.5.2)\n",
            "Requirement already satisfied: aenum>=3.1.11 in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (3.1.15)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (2.8.2)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (1.2.14)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.0->line-bot-sdk) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.0->line-bot-sdk) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.0->line-bot-sdk) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.0->line-bot-sdk) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.0->line-bot-sdk) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.0->line-bot-sdk) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->line-bot-sdk) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->line-bot-sdk) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->line-bot-sdk) (2023.11.17)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.0.3->line-bot-sdk) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.0.3->line-bot-sdk) (2.14.5)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.0.3->line-bot-sdk) (4.8.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->line-bot-sdk) (1.16.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->line-bot-sdk) (1.14.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.0.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: line-bot-sdk in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (2.0.7)\n",
            "Requirement already satisfied: aiohttp==3.9.0 in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (3.9.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (0.18.3)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (2.5.2)\n",
            "Requirement already satisfied: aenum>=3.1.11 in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (3.1.15)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (2.8.2)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from line-bot-sdk) (1.2.14)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.0->line-bot-sdk) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.0->line-bot-sdk) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.0->line-bot-sdk) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.0->line-bot-sdk) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.0->line-bot-sdk) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.0->line-bot-sdk) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->line-bot-sdk) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->line-bot-sdk) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->line-bot-sdk) (2023.11.17)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.0.3->line-bot-sdk) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.0.3->line-bot-sdk) (2.14.5)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.0.3->line-bot-sdk) (4.8.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->line-bot-sdk) (1.16.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->line-bot-sdk) (1.14.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.0.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement request (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for request\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the requests library\n",
        "import requests\n",
        "\n",
        "# API endpoint URL\n",
        "url = \"https://app.suggestlab.com/version-test/api/1.1/wf/morganus\"\n",
        "\n",
        "# Making a POST request to the API\n",
        "response = requests.post(url)\n",
        "\n",
        "# Check the response\n",
        "if response.status_code == 200:\n",
        "    # Processing the JSON response\n",
        "    data = response.json()\n",
        "    print(\"Data retrieved successfully:\")\n",
        "    print(data)\n",
        "else:\n",
        "    print(\"Failed to retrieve data\")"
      ],
      "metadata": {
        "id": "H0kTAvPmbGxJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "d479b9fd-05ae-4c4a-84ad-35792a3da7c7"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-0ddcfcd45fb6>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Processing the JSON response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data retrieved successfully:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;31m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m             \u001b[0;31m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRequestsJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to LINE bot"
      ],
      "metadata": {
        "id": "w9bQHB1tJ11G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, json"
      ],
      "metadata": {
        "id": "_xDoGH9LGVYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# แก้ channel_id และ channel_secret\n",
        "channel_id = \"????\"\n",
        "channel_secret = \"d0bd9cece91a713f1bc5724d64b72bfe\""
      ],
      "metadata": {
        "id": "ofxLQsIBGZQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Convertir el DataFrame a formato JSON\n",
        "json_data = matriz_precios_prejson.to_json(orient='records')\n",
        "\n",
        "# รัน cell เพื่อขอ Short-lived (30 days) channel access token\n",
        "def issueToken_short(client_id, client_secret):\n",
        "    endpoint = \"https://app.suggestlab.com/version-test/api/1.1/wf/morganus\"\n",
        "    header = {'Content-Type': 'application/json'}\n",
        "    body = {'grant_type': 'client_credentials',\n",
        "            'client_id': client_id,\n",
        "            'client_secret': client_secret}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(endpoint, json=body, headers=header)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            obj = json.loads(response.text)\n",
        "            return obj\n",
        "        else:\n",
        "            print(f\"Error en la solicitud. Código de estado: {response.status_code}\")\n",
        "            return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error en la solicitud HTTP: {e}\")\n",
        "        return None\n",
        "\n",
        "tokenDict = issueToken_short(channel_id, channel_secret)\n",
        "channelAccessToken = tokenDict['access_token']\n"
      ],
      "metadata": {
        "id": "8y-CB4KOJZkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convertir el DataFrame a formato JSON\n",
        "json_data = matriz_precios_prejson.to_json(orient='records')\n",
        "\n",
        "# รัน cell เพื่อขอ Short-lived (30 days) channel access token\n",
        "def issueToken_short(client_id, client_secret):\n",
        "  endpoint = \"https://app.suggestlab.com/version-test/api/1.1/wf/morganus\"\n",
        "  header = header = {'Content-Type': 'application/json'}\n",
        "  body = {'grant_type': 'client_credentials',\n",
        "          'client_id': client_id,\n",
        "          'client_secret': client_secret}\n",
        "  response = requests.post(endpoint, json=body, headers=header)\n",
        "  print(response)\n",
        "  obj = json.loads(response.text)\n",
        "  return obj\n",
        "\n",
        "tokenDict = issueToken_short(channel_id, channel_secret)\n",
        "channelAccessToken = tokenDict['access_token']\n",
        "tokenDict"
      ],
      "metadata": {
        "id": "FVCrLSYrGiWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create LINE bot object"
      ],
      "metadata": {
        "id": "pgltqN0lKAsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from linebot import LineBotApi"
      ],
      "metadata": {
        "id": "Jyx7_LAxJ_9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create app running on localhost (colab) by flask"
      ],
      "metadata": {
        "id": "rndhc-AFKLOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, abort\n",
        "from linebot import LineBotApi, WebhookHandler\n",
        "from linebot.exceptions import InvalidSignatureError\n",
        "from linebot.models import MessageEvent, TextMessage, TextSendMessage"
      ],
      "metadata": {
        "id": "6VmBDIxFKN2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "\n",
        "handler = WebhookHandler(channel_secret)\n",
        "\n",
        "@app.route(\"/webhook.site/5825b18a-f284-475d-9cb2-66d72574b2df\", methods=['POST'])\n",
        "def callback():\n",
        "    # get X-Line-Signature header value\n",
        "    signature = request.headers['X-Line-Signature']\n",
        "\n",
        "    # get request body as text\n",
        "    body = request.get_data(as_text=True)\n",
        "    print(\"# Webhook event:\\n\", body)\n",
        "    print('-'*100)\n",
        "\n",
        "    app.logger.info(\"Request body: \" + body)\n",
        "\n",
        "@handler.add(MessageEvent, message=TextMessage)\n",
        "def handle_message(event): # echo function\n",
        "    print(\"Message Return\\n:\", event)\n",
        "    line_bot_api.reply_message(event.reply_token,\n",
        "                               TextSendMessage(text=event.message.text))\n",
        "\n",
        "#print(\"# Webhook event:\\n\", body)"
      ],
      "metadata": {
        "id": "qvwzGTe6KTQE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}